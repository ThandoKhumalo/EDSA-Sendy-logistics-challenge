{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction <a name=\"introduction\"></a>\n",
    "\n",
    "**A model to predict the estimated time of delivery of orders, from the point of driver pickup to the point of arrival at final destination. The solution will help Sendy enhance customer communication and improve the reliability of its service; which will ultimately improve customer experience. In addition, the solution will enable Sendy to realise cost savings, and ultimately reduce the cost of doing business, through improved resource management and planning for order scheduling.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "1. [Introduction](#introduction)\n",
    "2. [Importing libraries](#Importing_libraries)\n",
    "3. [Importing datasets](#Importing_datasets)\n",
    "4. [A quick look at how our data is structured](#Data_structure)\n",
    "5. [Data Visualization](#visuals)\n",
    "    1. [Temperature distribution](#temperature)\n",
    "    2. [Vehicle types](#vehicle_types)\n",
    "    3. [Platform types](#platform_types)\n",
    "    4. [Personal or Business](#personal_or_business)\n",
    "    5. [Order placement](#order_placement)\n",
    "        1. [Order placement day of the month](#order_placement_day_of_the_month)\n",
    "        2. [Placement weekday](#placement_weekday)\n",
    "    6. [Order confirmation](#order_confirmation)\n",
    "        1. [Confirmation day of month](#confirmation_day_of_month)\n",
    "        2. [Confirmation weekday](#confirmation_weekday)\n",
    "6. [Data Preprocessing](#data_preprocessing)\n",
    "7. [Modeling](#modeling)\n",
    "    1. [Linear Regression Model](#linear_model)\n",
    "    2. [XGBoost](#xgb)\n",
    "    3. [Random Forest](#random_forest)\n",
    "    4. [Decision Tree](#decision_tree)\n",
    "8. [Conclusion](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries <a name=\"Importing_libraries\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install category_encoders\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "import xgboost as xgb\n",
    "import category_encoders as ce\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from datetime import timedelta\n",
    "from scipy.stats import uniform, randint \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing datasets <a name=\"Importing_datasets\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/Train.csv\")\n",
    "test = pd.read_csv(\"data/Test.csv\")\n",
    "riders = pd.read_csv(\"data/Riders.csv\")\n",
    "sample_submission = pd.read_csv(\"data/SampleSubmission.csv\")\n",
    "variable_definitions = pd.read_csv(\"data/VariableDefinitions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A quick look at how our data is structured <a name=\"Data_structure\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(variable_definitions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The training dataset has {train.shape[0]} rows and {train.shape[1]} columns.\") # Getting the total number of rows & columns in the training data.\n",
    "display(train.info())\n",
    "display(train.head()) # The 1st 5 rows.\n",
    "display(train.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The training dataset has {test.shape[0]} rows and {test.shape[1]} columns.\") # Getting the total number of rows & columns in the training data.\n",
    "display(test.info())\n",
    "display(test.head()) # The 1st 5 rows.\n",
    "display(test.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization <a name=\"visuals\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperature distribution <a name=\"temperature\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 2, figsize=(15, 7), sharex=True)\n",
    "axes[0].set_title(\"Train Data\")\n",
    "axes[1].set_title(\"Test Data\")\n",
    "sns.distplot(train[\"Temperature\"], color=\"blue\", ax=axes[0])\n",
    "sns.distplot(test[\"Temperature\"], color=\"red\", ax=axes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train mean {}\".format(train[\"Temperature\"].mean()))\n",
    "print(\"Train median {}\".format(train[\"Temperature\"].median()))\n",
    "print(\"Test mean {}\".format(test[\"Temperature\"].mean()))\n",
    "print(\"Test median {}\".format(test[\"Temperature\"].median()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean and median temperature values are pretty much the same, we can safely use either 1 to replace the missing temperature values in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_train_df = train.copy(deep=True)\n",
    "clean_test_df = test.copy(deep=True)\n",
    "clean_train_df[\"Temperature\"].fillna(clean_train_df[\"Temperature\"].mean(), inplace=True)\n",
    "clean_test_df[\"Temperature\"].fillna(clean_test_df[\"Temperature\"].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "replacing missing temperature values with the mean temperature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vehicle types <a name=\"vehicle_types\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 2, figsize=(15, 7), sharex=True)\n",
    "axes[0].set_title(\"Train data\")\n",
    "axes[1].set_title(\"Test data\")\n",
    "sns.countplot(x='Vehicle Type', data=train, ax=axes[0])\n",
    "sns.countplot(x='Vehicle Type', data=test, ax=axes[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from the **count plot** above we can see that there's only **one** vehicle type, so we can safely discard this column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Platform types <a name=\"platform_types\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 2, figsize=(15, 7), sharex=True)\n",
    "axes[0].set_title(\"Train data\")\n",
    "axes[1].set_title(\"Test data\")\n",
    "sns.countplot(x='Platform Type', data=train, ax=axes[0])\n",
    "sns.countplot(x='Platform Type', data=test, ax=axes[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have **four** different vehicle **platform types** which makes this feature very usefull as vehicle perfomance may vary drastically based on the platform type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Personal or business <a name=\"personal_or_business\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 2, figsize=(15, 7), sharex=True)\n",
    "axes[0].set_title(\"Train data\")\n",
    "axes[1].set_title(\"Test data\")\n",
    "sns.countplot(x='Personal or Business', data=train, ax=axes[0])\n",
    "sns.countplot(x='Personal or Business', data=test, ax=axes[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The majority of our riders fall under the **Business** category & this could affect how efficient the riders are at their jobs. Riders working for a business might try to improve their efficiency to boost their ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Order Placement <a name=\"order_placement\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Order placement day of the month <a name=\"order_placement_day_of_the_month\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 2, figsize=(15, 7), sharex=True)\n",
    "axes[0].set_title(\"Train data\")\n",
    "axes[1].set_title(\"Test data\")\n",
    "sns.countplot(x='Placement - Day of Month', data=train, ax=axes[0])\n",
    "sns.countplot(x='Placement - Day of Month', data=test, ax=axes[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Placement - Weekday (Mo = 1) <a name=\"placement_weekday\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 2, figsize=(15, 7), sharex=True)\n",
    "axes[0].set_title(\"Train data\")\n",
    "axes[1].set_title(\"Test data\")\n",
    "sns.countplot(x='Placement - Weekday (Mo = 1)', data=train, ax=axes[0])\n",
    "sns.countplot(x='Placement - Weekday (Mo = 1)', data=test, ax=axes[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Order Confirmation <a name=\"order_confirmation\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confirmation - Day of Month <a name=\"confirmation_day_of_month\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 2, figsize=(15, 7), sharex=True)\n",
    "axes[0].set_title(\"Train data\")\n",
    "axes[1].set_title(\"Test data\")\n",
    "sns.countplot(x='Confirmation - Day of Month', data=train, ax=axes[0])\n",
    "sns.countplot(x='Confirmation - Day of Month', data=test, ax=axes[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confirmation - Weekday (Mo = 1) <a name=\"confirmation_weekday\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 2, figsize=(15, 7), sharex=True)\n",
    "axes[0].set_title(\"Train data\")\n",
    "axes[1].set_title(\"Test data\")\n",
    "sns.countplot(x='Confirmation - Weekday (Mo = 1)', data=train, ax=axes[0])\n",
    "sns.countplot(x='Confirmation - Weekday (Mo = 1)', data=test, ax=axes[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the 4 count plots we have **above**, we can see that most of the orders get confirmned on the day they were placed. We can safely discard either one of the placement or confimation date data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 2, figsize=(15, 7), sharex=True)\n",
    "axes[0].set_title(\"Train data\")\n",
    "axes[1].set_title(\"Test data\")\n",
    "sns.distplot(train[\"Precipitation in millimeters\"], ax=axes[0])\n",
    "sns.distplot(test[\"Precipitation in millimeters\"], ax=axes[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rainfall can have a huge impact on delivery time, so instead of just dropping the precipitation column we'll just assume that there wasn't any rainfall on the days with missing data (this will be represented by a **zero** and the days with rainfall will be represented by a **one**). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing <a name='data_preprocessing'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function to convert the time features into the number of **seconds after midnight**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seconds_after_midnight(input_df):\n",
    "    df = input_df.copy(deep=True)\n",
    "    placement_time = []\n",
    "    confirmation_time = []\n",
    "    arrival_at_pickup_time = []\n",
    "    pickup_time = []\n",
    "    arrival_at_destination_time = []\n",
    "    for time in df[\"Placement - Time\"]:\n",
    "        i = 0\n",
    "        if time[-2:] == \"PM\":\n",
    "            i = 12\n",
    "        split_time = time.split(\":\")\n",
    "        placement_time.append(timedelta(hours=int(split_time[0].replace(\" \", \"\")) + i, minutes=int(split_time[1]), seconds=int(split_time[2][:2])).total_seconds())\n",
    "    for time in df[\"Confirmation - Time\"]:\n",
    "        i = 0\n",
    "        if time[-2:] == \"PM\":\n",
    "            i = 12\n",
    "        split_time = time.split(\":\")\n",
    "        confirmation_time.append(timedelta(hours=int(split_time[0].replace(\" \", \"\")) + i, minutes=int(split_time[1]), seconds=int(split_time[2][:2])).total_seconds())\n",
    "    for time in df[\"Arrival at Pickup - Time\"]:\n",
    "        i = 0\n",
    "        if time[-2:] == \"PM\":\n",
    "            i = 12\n",
    "        split_time = time.split(\":\")\n",
    "        arrival_at_pickup_time.append(timedelta(hours=int(split_time[0].replace(\" \", \"\")) + i, minutes=int(split_time[1]), seconds=int(split_time[2][:2])).total_seconds())\n",
    "    for time in df[\"Pickup - Time\"]:\n",
    "        i = 0\n",
    "        if time[-2:] == \"PM\":\n",
    "            i = 12\n",
    "        split_time = time.split(\":\")\n",
    "        pickup_time.append(timedelta(hours=int(split_time[0].replace(\" \", \"\")) + i, minutes=int(split_time[1]), seconds=int(split_time[2][:2])).total_seconds())\n",
    "    df[\"placement_time\"] = placement_time\n",
    "    df[\"confirmation_time\"] = confirmation_time\n",
    "    df[\"arrival_at_pickup_time\"] = arrival_at_pickup_time\n",
    "    df[\"pickup_time\"] = pickup_time\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fuction for some data preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(df):\n",
    "    duplicate_df = df.copy(deep=True)\n",
    "    duplicate_df[\"Temperature\"].fillna(round(duplicate_df[\"Temperature\"].mean(), 0), inplace=True)\n",
    "    columns_to_drop = [\"Vehicle Type\",\n",
    "                       \"Placement - Time\", \"Confirmation - Day of Month\",\n",
    "                       \"Confirmation - Weekday (Mo = 1)\", \"Confirmation - Time\",\n",
    "                       \"Arrival at Pickup - Day of Month\", \"Arrival at Pickup - Weekday (Mo = 1)\",\n",
    "                       \"Arrival at Pickup - Time\", \"Pickup - Time\",\n",
    "                       \"Pickup Lat\", \"Pickup Long\", \"Destination Lat\", \"Destination Long\", \"Rider Id\",\n",
    "                       \"Order No\", \"User Id\"]\n",
    "    duplicate_df[\"Personal or Business\"] = duplicate_df[\"Personal or Business\"].replace([\"Personal\"], 0)\n",
    "    duplicate_df[\"Personal or Business\"] = duplicate_df[\"Personal or Business\"].replace([\"Business\"], 1)\n",
    "    duplicate_df.drop(columns_to_drop, axis=1, inplace=True)\n",
    "    return duplicate_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the data contained in the **Personal or Business** column into a binary format. (0s & 1s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
